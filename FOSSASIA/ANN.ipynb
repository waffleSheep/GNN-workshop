{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvaM5zJe2wMJ"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solving a simple linear system with pytorch and gradient descent"
      ],
      "metadata": {
        "id": "Ycvz-7cy3gNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$w+3x+2y-z=9\\\\\n",
        "5w+2x+y-2z=4\\\\\n",
        "x+2y+4z=24\\\\\n",
        "w+x-y-3z=-12$$"
      ],
      "metadata": {
        "id": "zVVdPM9h3tIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above is a series of linear equations that are represented in the matrice format: `Ax = b`. We will first represent each matrix as a torch tensor."
      ],
      "metadata": {
        "id": "OqTDuFZ_Epgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "A=\n",
        "\\begin{bmatrix}\n",
        "1 & 3 & 2 & -1\\\\\n",
        "5 & 2 & 1 & -2\\\\\n",
        "0 & 1 & 2 & 4\\\\\n",
        "1 & 1 & -1 & -3\n",
        "\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "3COdWS2XFIHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.tensor([[1,3,2,-1],[5,2,1,-2],[0,1,2,4],[1,1,-1,-3]]).float()\n",
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEB-bUNk3hmC",
        "outputId": "c20af6fd-56c4-4049-ca37-c3a8b4087ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  3.,  2., -1.],\n",
              "        [ 5.,  2.,  1., -2.],\n",
              "        [ 0.,  1.,  2.,  4.],\n",
              "        [ 1.,  1., -1., -3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\mathbf{y}=\n",
        "\\begin{bmatrix}\n",
        "9\\\\\n",
        "4\\\\\n",
        "24\\\\\n",
        "-12\n",
        "\\end{bmatrix}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "38shsTSl3834"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.tensor([9,4,24,-12]).float()\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2VfOfLU34wF",
        "outputId": "3a03d529-9f2e-4fd7-d2d2-20b0efc5a454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  9.,   4.,  24., -12.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\mathbf{x}=\n",
        "\\begin{bmatrix}\n",
        "w\\\\\n",
        "x\\\\\n",
        "y\\\\\n",
        "z\n",
        "\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "yUAoZPRa4QPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For x, we do not know the specific numbers, so first we will initialise random numbers"
      ],
      "metadata": {
        "id": "uhHcUKM3FPce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn([4], requires_grad=True)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVdZDtRw4NCv",
        "outputId": "a96978f7-d0d1-4e01-b6a5-9029323fc9b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2719, -0.1371,  0.5924, -0.0146], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$L = ||A\\mathbf{x}-\\mathbf{y}||^2_2$$"
      ],
      "metadata": {
        "id": "UyXezzaQ4U0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For loss, we are using L2 Norm aka Mean Square Error. We will take the difference between our actual `y` and our predicted y, `Ax` and square it to allow it to be positive. Absolute is not used as it is harder to differentiate it"
      ],
      "metadata": {
        "id": "MIzZ5ch8FYrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.MSELoss()\n",
        "L = loss(torch.matmul(A, x), y)\n",
        "L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsyw681_4SP-",
        "outputId": "f35b013f-a37e-40f2-d06d-3ebaf68135d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(187.1334, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD([x], lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "eJopUgUc4XNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    L = loss(torch.matmul(A, x), y)\n",
        "    L.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "c7XUXfZy4wNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6WfZLit43E4",
        "outputId": "fe7337b3-8d78-4e11-8c3e-a16b9665d0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 2.0000, 3.0000, 4.0000], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we know how gradient descent works, let us do something harder: Creating a NN"
      ],
      "metadata": {
        "id": "kJlDgLyQHc9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Neural Network"
      ],
      "metadata": {
        "id": "fEGSWWPkHpma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "KabbQzuE45DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define our neural network by subclassing `nn.Module`, and\n",
        "initialize the neural network layers in `__init__`. `forward` defines how the data will be pass through the neural network"
      ],
      "metadata": {
        "id": "HpneCMCiK6yD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT RUN THIS AT ALL\n",
        "class Ne(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "      pass"
      ],
      "metadata": {
        "id": "i5wf4v-bEed6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are making a model to classify MNIST (Some number dataset ðŸ™„) which contains images of numbers. First, we need to transform the image to numbers. We can do this by flattening a 28 by 28 image to a 784 arraylist, with the number being a grayscale number from 0 to 255. Let us add that in!"
      ],
      "metadata": {
        "id": "bPS0yY0aMPAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT RUN THIS AT ALL\n",
        "class Neu(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "      pass"
      ],
      "metadata": {
        "id": "575HkIquLzxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We added `Flatten` which causes the image to be 1 flat array"
      ],
      "metadata": {
        "id": "qsmUYLQDNGRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need some layers of nodes. Luckily, torch is a good library and gives us the method `linear` to create a layer of nodes\n",
        "\n",
        "```\n",
        "nn.Linear(in_features=(number of input nodes), out_features=(number of output nodes))\n",
        "```\n",
        "\n",
        "We also need to make sure the output goes through a non-linear function to allow our Neural Network to model any functions. We can use `relu` activation function for this.\n",
        "\n",
        "```\n",
        "nn.ReLU()(input)\n",
        "```\n",
        "\n",
        "\n",
        "However, at the output, we cannot just give numbers, what do they mean? We need to scale them to between 0 and 1 to represent the probability of each class. `dim` is the dimension along which the inputs are softmaxxed\n",
        "\n",
        "```\n",
        "nn.Softmax(dim=n)()\n",
        "```"
      ],
      "metadata": {
        "id": "PSEmQ7ezNOmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, how do we make sure that it goes through all the layers sequentially. We can use `nn.Sequential` which is a container of layers that the data passes through"
      ],
      "metadata": {
        "id": "Cs7xxG_-OYRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT RUN THIS AT ALL\n",
        "class Neural(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(784, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10),\n",
        "            nn.Softmax\n",
        "        )\n",
        "                \n",
        "    def forward(self, x):\n",
        "      pass"
      ],
      "metadata": {
        "id": "JkOiUPgjNNoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us finish it by coding the forward function"
      ],
      "metadata": {
        "id": "dWPk_p4yQPzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neural(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.stack = nn.Sequential(\n",
        "            nn.Linear(784, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "                \n",
        "    def forward(self, x):\n",
        "      x = self.flatten(x)\n",
        "      perc = self.stack(x)\n",
        "      return perc"
      ],
      "metadata": {
        "id": "YY_elXHfNaQg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}